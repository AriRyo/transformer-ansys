{"cells":[{"cell_type":"markdown","metadata":{"id":"M1oqh0F6W3ad"},"source":["# FomulaBEAT\n","\n","変更点\n","- デコーダのみで学習させる\n","- TransformerDecoderLayerをスクラッチで書く\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["version = '03'\n","model_dir = './model/' + version\n","data_path = 'data/eq03.txt'"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2860,"status":"ok","timestamp":1611303247694,"user":{"displayName":"Karan Sonawane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWjX1_4b0iu2fEkjbIRKIHq-Molc5N_CnbcU75=s64","userId":"05479461208077736330"},"user_tz":-330},"id":"IMnymRDLe0hi","outputId":"706de1c8-715a-41e2-bdcf-3caa67125bf8"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/arifuku/ymmtlab/TransformerAnsys/.venv/lib/python3.10/site-packages/torchtext/data/__init__.py:4: UserWarning: \n","/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n","Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n","  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n","/home/arifuku/ymmtlab/TransformerAnsys/.venv/lib/python3.10/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n","/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n","Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n","  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n","/home/arifuku/ymmtlab/TransformerAnsys/.venv/lib/python3.10/site-packages/torchtext/utils.py:4: UserWarning: \n","/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n","Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n","  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"]}],"source":["from pathlib import Path\n","import math\n","import time\n","from collections import Counter\n","from tqdm import tqdm\n","import torch\n","from torch.utils.data import random_split\n","import torch.nn as nn\n","from torch import Tensor\n","from torch.nn import (\n","    TransformerEncoder, TransformerDecoder,\n","    TransformerEncoderLayer, TransformerDecoderLayer\n",")\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import vocab\n","from torchtext.utils import download_from_url, extract_archive\n","import torch.nn.functional as F\n"]},{"cell_type":"markdown","metadata":{},"source":["パラメータの事前設定"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","torch.set_printoptions(linewidth=100)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","model_dir_path = Path(model_dir)\n","if not model_dir_path.exists():\n","    model_dir_path.mkdir(parents=True)"]},{"cell_type":"markdown","metadata":{},"source":["データの取得"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def read_equation_file(file_path):\n","    with open(file_path, 'r') as file:\n","        lines = file.readlines()\n","    src_data, tgt_data = [], []\n","    for line in lines:\n","        src, tgt = line.strip().split(' => ')\n","        src_data.append(src)\n","        tgt_data.append(tgt)\n","    return src_data, tgt_data\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['+ 4 6', '- 3 - 1 + 6 3', '+ 8 7'] ['4 6 +', '3 1 6 3 + - -', '8 7 +']\n"]}],"source":["# ファイルを読み込み、数式データを取得\n","src_data, tgt_data = read_equation_file(data_path)\n","print(src_data[:3], tgt_data[:3])\n"]},{"cell_type":"markdown","metadata":{},"source":["辞書データの作成"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["\n","SPECIALS = ['<unk>', '<pad>', '<start>', '<end>']\n","\n","def build_vocab(texts):\n","    vocab = {}\n","    idx = 0\n","    # 数字の語彙定義\n","    for i in range(10):\n","        vocab[str(i)] = idx\n","        idx += 1\n","    # 特別語の語彙定義\n","    for sp in SPECIALS:\n","        vocab[sp] = idx\n","        idx += 1\n","    # その他の文字の語彙定義\n","    for text in texts:\n","        for char in text:\n","            if char not in vocab:\n","                vocab[char] = idx\n","                idx += 1\n","    return vocab\n","\n","\n","def convert_text_to_indexes(text, vocab):\n","    # <start> と <end> トークンを追加して数値化\n","    return [vocab['<start>']] + [vocab[char] if char in vocab else vocab['<unk>'] for char in text] + [vocab['<end>']]\n","\n","# データを処理して Train と Valid に分ける関数\n","# データを処理して Train と Valid に分ける関数\n","def data_process_split(src_texts, tgt_texts, vocab_src, vocab_tgt, valid_size=0.2):\n","    # データを数値化\n","    data = []\n","    for (src, tgt) in zip(src_texts, tgt_texts):\n","        src_tensor = torch.tensor(convert_text_to_indexes(src, vocab_src), dtype=torch.long)\n","        tgt_tensor = torch.tensor(convert_text_to_indexes(tgt, vocab_tgt), dtype=torch.long)\n","        data.append((src_tensor, tgt_tensor))\n","    \n","    # データのサイズを計算して、訓練データと検証データに分割\n","    data_size = len(data)\n","    valid_size = int(valid_size * data_size)\n","    train_size = data_size - valid_size\n","\n","    # PyTorchのrandom_splitを使って分割\n","    train_data, valid_data = random_split(data, [train_size, valid_size])\n","    \n","    return train_data, valid_data\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '<unk>': 10, '<pad>': 11, '<start>': 12, '<end>': 13, ' ': 14, '+': 15, '-': 16}\n"]}],"source":["# 辞書と逆辞書を構築\n","vocab_src = build_vocab(src_data)\n","vocab_tgt = build_vocab(tgt_data)\n","\n","print(vocab_tgt)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["インデックス化された文章\n","Input: tensor([12, 16, 15,  5, 15, 14, 15, 14, 15,  5, 15,  6, 15,  7, 13])\n","Output: tensor([12,  5, 14,  5, 14,  6, 14, 15, 14,  7, 14, 15, 14, 16, 13])\n","元に戻した文章\n","Input: - 5 + + 5 6 7\n","Output: 5 5 6 + 7 + -\n"]}],"source":["\n","# データを数値化\n","train_data, valid_data = data_process_split(src_data, tgt_data, vocab_src, vocab_tgt)\n","\n","# 結果の確認\n","print('インデックス化された文章')\n","print(f\"Input: {train_data[0][0]}\\nOutput: {train_data[0][1]}\")\n","\n","# インデックスから元の文字列に戻す\n","def convert_indexes_to_text(indexes:list, vocab):\n","    reverse_vocab = {idx: token for token, idx in vocab.items()}\n","    return ''.join([reverse_vocab[idx] for idx in indexes if idx in reverse_vocab and reverse_vocab[idx] not in ['<start>', '<end>', '<pad>']])\n","\n","print('元に戻した文章')\n","print(f\"Input: {convert_indexes_to_text(train_data[0][0].tolist(), vocab_src)}\")\n","print(f\"Output: {convert_indexes_to_text(train_data[0][1].tolist(), vocab_tgt)}\")\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["batch_size = 128\n","PAD_IDX = vocab_src['<pad>']\n","START_IDX = vocab_src['<start>']\n","END_IDX = vocab_src['<end>']\n","\n","def generate_batch(data_batch):\n","    \n","    batch_src, batch_tgt = [], []\n","    for src, tgt in data_batch:\n","        batch_src.append(src)\n","        batch_tgt.append(tgt)\n","        \n","    batch_src = pad_sequence(batch_src, padding_value=PAD_IDX)\n","    batch_tgt = pad_sequence(batch_tgt, padding_value=PAD_IDX)\n","    \n","    return batch_src, batch_tgt\n","\n","train_iter = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=generate_batch)\n","valid_iter = DataLoader(valid_data, batch_size=batch_size, shuffle=True, collate_fn=generate_batch)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["80000"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["len(train_data)"]},{"cell_type":"markdown","metadata":{},"source":["Transoformerの設定"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["class TokenEmbedding(nn.Module):\n","    \n","    def __init__(self, vocab_size, embedding_size):\n","        \n","        super(TokenEmbedding, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=PAD_IDX)\n","        self.embedding_size = embedding_size\n","        \n","    def forward(self, tokens: Tensor):\n","        return self.embedding(tokens.long()) * math.sqrt(self.embedding_size)\n","    \n","    \n","class PositionalEncoding(nn.Module):\n","    \n","    def __init__(self, embedding_size: int, dropout: float, maxlen: int = 5000):\n","        super(PositionalEncoding, self).__init__()\n","        \n","        den = torch.exp(-torch.arange(0, embedding_size, 2) * math.log(10000) / embedding_size)\n","        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n","        embedding_pos = torch.zeros((maxlen, embedding_size))\n","        embedding_pos[:, 0::2] = torch.sin(pos * den)\n","        embedding_pos[:, 1::2] = torch.cos(pos * den)\n","        embedding_pos = embedding_pos.unsqueeze(-2)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer('embedding_pos', embedding_pos)\n","\n","    def forward(self, token_embedding: Tensor):\n","        return self.dropout(token_embedding + self.embedding_pos[: token_embedding.size(0), :])\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["\n","class TransformerDecoderLayerScratch(nn.Module):\n","    def __init__(self, d_model, nhead, dim_feedforward, dropout=0.1):\n","        super(TransformerDecoderLayerScratch, self).__init__()\n","        # Self-attention for the decoder\n","        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n","        # Multihead attention for attending to encoder outputs (memory)\n","        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n","        # Feedforward layers\n","        self.linear1 = nn.Linear(d_model, dim_feedforward)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear2 = nn.Linear(dim_feedforward, d_model)\n","        # Layer normalization layers\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        # Dropout\n","        self.dropout1 = nn.Dropout(dropout)\n","        self.dropout2 = nn.Dropout(dropout)\n","        self.dropout3 = nn.Dropout(dropout)\n","\n","    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n","        # Self-attention\n","        tgt2, _ = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask, key_padding_mask=tgt_key_padding_mask)\n","        tgt = tgt + self.dropout1(tgt2)\n","        tgt = self.norm1(tgt)\n","        \n","        # Attention with the encoder outputs (memory)\n","        tgt2, _ = self.multihead_attn(tgt, memory, memory, attn_mask=memory_mask, key_padding_mask=memory_key_padding_mask)\n","        tgt = tgt + self.dropout2(tgt2)\n","        tgt = self.norm2(tgt)\n","        \n","        # Feedforward network\n","        tgt2 = self.linear2(self.dropout(F.relu(self.linear1(tgt))))\n","        tgt = tgt + self.dropout3(tgt2)\n","        tgt = self.norm3(tgt)\n","\n","        return tgt\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["\n","class Seq2SeqTransformer(nn.Module):\n","    \n","    def __init__(\n","        self, num_encoder_layers: int, num_decoder_layers: int,\n","        embedding_size: int, vocab_size_src: int, vocab_size_tgt: int,\n","        dim_feedforward:int = 512, dropout:float = 0.1, nhead:int = 8\n","    ):\n","        \n","        super(Seq2SeqTransformer, self).__init__()\n","\n","        self.token_embedding_src = TokenEmbedding(vocab_size_src, embedding_size)\n","        self.positional_encoding = PositionalEncoding(embedding_size, dropout=dropout)\n","        \n","        self.token_embedding_tgt = TokenEmbedding(vocab_size_tgt, embedding_size)\n","        self.decoder_layer = TransformerDecoderLayerScratch(\n","            d_model=embedding_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout\n","        )\n","        \n","        self.output = nn.Linear(embedding_size, vocab_size_tgt)\n","\n","    def forward(\n","        self, src: Tensor, tgt: Tensor,\n","        mask_src: Tensor, mask_tgt: Tensor,\n","        padding_mask_src: Tensor, padding_mask_tgt: Tensor,\n","        memory_key_padding_mask: Tensor\n","    ):\n","        embedding_src = self.positional_encoding(self.token_embedding_src(src))\n","        # memory = self.transformer_encoder(embedding_src, mask_src, padding_mask_src)\n","        embedding_tgt = self.positional_encoding(self.token_embedding_tgt(tgt))\n","        outs = self.decoder_layer(\n","            embedding_tgt, embedding_src, mask_tgt, None,\n","            padding_mask_tgt, memory_key_padding_mask\n","        )\n","        return self.output(outs)\n","\n","    def decode(self, tgt: Tensor, memory: Tensor, mask_tgt: Tensor):\n","        return self.decoder_layer(self.positional_encoding(self.token_embedding_tgt(tgt)), memory, mask_tgt)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def create_mask(src, tgt, PAD_IDX):\n","    \n","    seq_len_src = src.shape[0]\n","    seq_len_tgt = tgt.shape[0]\n","\n","    mask_src = torch.zeros((seq_len_src, seq_len_src), device=device).type(torch.bool)\n","    mask_tgt = generate_square_subsequent_mask(seq_len_tgt)\n","\n","    padding_mask_src = (src == PAD_IDX).transpose(0, 1)\n","    padding_mask_tgt = (tgt == PAD_IDX).transpose(0, 1)\n","    \n","    return mask_src, mask_tgt, padding_mask_src, padding_mask_tgt\n","\n","\n","def generate_square_subsequent_mask(seq_len):\n","    mask = (torch.triu(torch.ones((seq_len, seq_len), device=device)) == 1).transpose(0, 1)\n","    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","    return mask"]},{"cell_type":"markdown","metadata":{},"source":["学習の定義"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def train(model, data, optimizer, criterion, PAD_IDX):\n","    \n","    model.train()\n","    losses = 0\n","    for src, tgt in tqdm(data):\n","        \n","        src = src.to(device)\n","        tgt = tgt.to(device)\n","\n","        input_tgt = tgt[:-1, :]\n","\n","        mask_src, mask_tgt, padding_mask_src, padding_mask_tgt = create_mask(src, input_tgt, PAD_IDX)\n","\n","        logits = model(\n","            src=src, tgt=input_tgt,\n","            mask_src=mask_src, mask_tgt=mask_tgt,\n","            padding_mask_src=padding_mask_src, padding_mask_tgt=padding_mask_tgt,\n","            memory_key_padding_mask=padding_mask_src\n","        )\n","\n","        optimizer.zero_grad()\n","        output_tgt = tgt[1:, :]\n","        loss = criterion(logits.reshape(-1, logits.shape[-1]), output_tgt.reshape(-1))\n","        loss.backward()\n","\n","        optimizer.step()\n","        losses += loss.item()\n","        \n","    return losses / len(data)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["\n","def evaluate(model, data, criterion, PAD_IDX):\n","    \n","    model.eval()\n","    losses = 0\n","    for src, tgt in data:\n","        \n","        src = src.to(device)\n","        tgt = tgt.to(device)\n","\n","        input_tgt = tgt[:-1, :]\n","\n","        mask_src, mask_tgt, padding_mask_src, padding_mask_tgt = create_mask(src, input_tgt, PAD_IDX)\n","\n","        logits = model(\n","            src=src, tgt=input_tgt,\n","            mask_src=mask_src, mask_tgt=mask_tgt,\n","            padding_mask_src=padding_mask_src, padding_mask_tgt=padding_mask_tgt,\n","            memory_key_padding_mask=padding_mask_src\n","        )\n","        \n","        output_tgt = tgt[1:, :]\n","        loss = criterion(logits.reshape(-1, logits.shape[-1]), output_tgt.reshape(-1))\n","        losses += loss.item()\n","        \n","    return losses / len(data)"]},{"cell_type":"markdown","metadata":{},"source":["設定"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["vocab_size_src = len(vocab_src)\n","vocab_size_tgt = len(vocab_tgt)\n","embedding_size = 4\n","nhead = 1\n","dim_feedforward = 4\n","num_encoder_layers = 1\n","num_decoder_layers = 1\n","dropout = 0\n","# vocab_size_src = len(vocab_src)\n","# vocab_size_tgt = len(vocab_tgt)\n","# embedding_size = 240\n","# nhead = 8\n","# dim_feedforward = 100\n","# num_encoder_layers = 2\n","# num_decoder_layers = 2\n","# dropout = 0.1\n","\n","model = Seq2SeqTransformer(\n","    num_encoder_layers=num_encoder_layers,\n","    num_decoder_layers=num_decoder_layers,\n","    embedding_size=embedding_size,\n","    vocab_size_src=vocab_size_src, vocab_size_tgt=vocab_size_tgt,\n","    dim_feedforward=dim_feedforward,\n","    dropout=dropout, nhead=nhead\n",")\n","\n","for p in model.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)\n","\n","model = model.to(device)\n","\n","criterion = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n","\n","optimizer = torch.optim.Adam(model.parameters())"]},{"cell_type":"markdown","metadata":{},"source":["モデルの調査"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Seq2SeqTransformer(\n","  (token_embedding_src): TokenEmbedding(\n","    (embedding): Embedding(17, 4, padding_idx=11)\n","  )\n","  (positional_encoding): PositionalEncoding(\n","    (dropout): Dropout(p=0, inplace=False)\n","  )\n","  (token_embedding_tgt): TokenEmbedding(\n","    (embedding): Embedding(17, 4, padding_idx=11)\n","  )\n","  (decoder_layer): TransformerDecoderLayerScratch(\n","    (self_attn): MultiheadAttention(\n","      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n","    )\n","    (multihead_attn): MultiheadAttention(\n","      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n","    )\n","    (linear1): Linear(in_features=4, out_features=4, bias=True)\n","    (dropout): Dropout(p=0, inplace=False)\n","    (linear2): Linear(in_features=4, out_features=4, bias=True)\n","    (norm1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n","    (norm2): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n","    (norm3): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n","    (dropout1): Dropout(p=0, inplace=False)\n","    (dropout2): Dropout(p=0, inplace=False)\n","    (dropout3): Dropout(p=0, inplace=False)\n","  )\n","  (output): Linear(in_features=4, out_features=17, bias=True)\n",")\n"]}],"source":["print(model)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["22 層\n","\n","層名: token_embedding_src.embedding.weight\n","形状: torch.Size([17, 4])\n","値: Parameter containing:\n","tensor([[-0.1556,  0.3227, -0.3112, -0.1144],\n","        [ 0.0189,  0.3038, -0.3842, -0.2972],\n","        [ 0.4724, -0.3318,  0.0431,  0.0655],\n","        [-0.2612, -0.1869, -0.4495,  0.0242],\n","        [-0.4885,  0.1143,  0.3369,  0.3918],\n","        [-0.4730, -0.2358, -0.5093, -0.1757],\n","        [-0.1245, -0.3616, -0.1465, -0.2224],\n","        [ 0.0900, -0.0809, -0.4698,  0.0967],\n","        [-0.1259,  0.0021,  0.1130, -0.3577],\n","        [ 0.0074,  0.1421,  0.3809,  0.5034],\n","        [-0.4569, -0.1839,  0.0345, -0.4492],\n","        [-0.3190, -0.0924, -0.5344, -0.2240],\n","        [ 0.0706, -0.4735,  0.3436, -0.4156],\n","        [ 0.2067,  0.3581, -0.2850,  0.3873],\n","        [-0.0940,  0.2464,  0.2866, -0.2950],\n","        [-0.3049, -0.0253, -0.0247,  0.3094],\n","        [-0.1551, -0.2533, -0.2452, -0.4308]], device='cuda:0', requires_grad=True)\n","\n","層名: token_embedding_tgt.embedding.weight\n","形状: torch.Size([17, 4])\n","値: Parameter containing:\n","tensor([[ 0.0324,  0.2610,  0.2190,  0.3733],\n","        [ 0.4267, -0.0080,  0.3838,  0.0255],\n","        [ 0.1170,  0.2168, -0.2878,  0.4978],\n","        [ 0.3747,  0.2155, -0.0637, -0.3140],\n","        [-0.0654, -0.1419, -0.1552,  0.1893],\n","        [-0.0480, -0.1991,  0.4654,  0.1572],\n","        [-0.1818,  0.2855,  0.1737,  0.3436],\n","        [-0.4687,  0.1409, -0.1420,  0.2875],\n","        [ 0.4950, -0.2629, -0.1970, -0.1635],\n","        [-0.0804, -0.2011,  0.4071,  0.0829],\n","        [ 0.0201, -0.2446,  0.3560, -0.3782],\n","        [ 0.1547,  0.4505, -0.4918,  0.4693],\n","        [-0.0213, -0.0640, -0.5058,  0.0057],\n","        [-0.0734, -0.0520, -0.4613, -0.3732],\n","        [ 0.3106, -0.0344, -0.0840, -0.1552],\n","        [ 0.0939,  0.1636,  0.1014,  0.1350],\n","        [-0.1464,  0.0631,  0.3426, -0.2807]], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.self_attn.in_proj_weight\n","形状: torch.Size([12, 4])\n","値: Parameter containing:\n","tensor([[ 0.1578, -0.3591, -0.1625, -0.5728],\n","        [ 0.1127,  0.0700,  0.4609,  0.1051],\n","        [-0.5745,  0.0213,  0.4167,  0.0067],\n","        [ 0.5222,  0.5001,  0.4325,  0.1062],\n","        [ 0.4442,  0.0216, -0.0510,  0.3059],\n","        [-0.3715, -0.1948, -0.5372, -0.2830],\n","        [ 0.5276, -0.0078,  0.2664,  0.1947],\n","        [-0.5629, -0.3376,  0.2080, -0.3892],\n","        [-0.4455,  0.4498,  0.0563, -0.2663],\n","        [ 0.4722, -0.2933, -0.2482, -0.4582],\n","        [ 0.3978, -0.3025, -0.5077, -0.4069],\n","        [-0.3220, -0.3180,  0.5853, -0.3094]], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.self_attn.in_proj_bias\n","形状: torch.Size([12])\n","値: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.self_attn.out_proj.weight\n","形状: torch.Size([4, 4])\n","値: Parameter containing:\n","tensor([[-0.4332,  0.3669, -0.4496,  0.8059],\n","        [ 0.4760,  0.6752,  0.4721,  0.0689],\n","        [-0.1968, -0.7230,  0.0974,  0.7470],\n","        [ 0.5760,  0.2601, -0.7726, -0.1038]], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.self_attn.out_proj.bias\n","形状: torch.Size([4])\n","値: Parameter containing:\n","tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.multihead_attn.in_proj_weight\n","形状: torch.Size([12, 4])\n","値: Parameter containing:\n","tensor([[-0.2034,  0.1349, -0.4344, -0.0976],\n","        [ 0.0813, -0.4485, -0.1345, -0.0453],\n","        [-0.1486,  0.1000,  0.0702, -0.1963],\n","        [-0.2389,  0.1311,  0.5252, -0.1685],\n","        [ 0.4431,  0.5445, -0.0287, -0.4287],\n","        [ 0.3316,  0.0114,  0.5128,  0.4545],\n","        [ 0.0958, -0.5798, -0.3218, -0.1260],\n","        [ 0.1019, -0.1324, -0.2966,  0.4129],\n","        [-0.3957,  0.5221,  0.4742,  0.3524],\n","        [ 0.1253, -0.2511, -0.2863, -0.4623],\n","        [-0.2640, -0.2231,  0.0285,  0.4419],\n","        [ 0.3340, -0.5981, -0.2067,  0.3746]], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.multihead_attn.in_proj_bias\n","形状: torch.Size([12])\n","値: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.multihead_attn.out_proj.weight\n","形状: torch.Size([4, 4])\n","値: Parameter containing:\n","tensor([[-0.0680,  0.3754, -0.3687, -0.0317],\n","        [-0.1762, -0.1042, -0.1219, -0.4103],\n","        [ 0.7055,  0.5955, -0.7922, -0.5947],\n","        [-0.1864, -0.0831, -0.5271, -0.7687]], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.multihead_attn.out_proj.bias\n","形状: torch.Size([4])\n","値: Parameter containing:\n","tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.linear1.weight\n","形状: torch.Size([4, 4])\n","値: Parameter containing:\n","tensor([[ 0.3293, -0.7429,  0.4575, -0.1290],\n","        [-0.2250, -0.5970, -0.0171, -0.1619],\n","        [ 0.6334,  0.6050,  0.5903, -0.0685],\n","        [-0.2308,  0.6339,  0.3504, -0.0970]], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.linear1.bias\n","形状: torch.Size([4])\n","値: Parameter containing:\n","tensor([ 0.1574, -0.1754,  0.4057, -0.2098], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.linear2.weight\n","形状: torch.Size([4, 4])\n","値: Parameter containing:\n","tensor([[ 0.3864,  0.3908,  0.3900, -0.4476],\n","        [ 0.3549, -0.7591,  0.3773, -0.0732],\n","        [ 0.6068, -0.6649, -0.4928,  0.0668],\n","        [ 0.8224, -0.8402, -0.6531, -0.4023]], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.linear2.bias\n","形状: torch.Size([4])\n","値: Parameter containing:\n","tensor([ 0.3775,  0.0224,  0.4951, -0.0316], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.norm1.weight\n","形状: torch.Size([4])\n","値: Parameter containing:\n","tensor([1., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.norm1.bias\n","形状: torch.Size([4])\n","値: Parameter containing:\n","tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.norm2.weight\n","形状: torch.Size([4])\n","値: Parameter containing:\n","tensor([1., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.norm2.bias\n","形状: torch.Size([4])\n","値: Parameter containing:\n","tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.norm3.weight\n","形状: torch.Size([4])\n","値: Parameter containing:\n","tensor([1., 1., 1., 1.], device='cuda:0', requires_grad=True)\n","\n","層名: decoder_layer.norm3.bias\n","形状: torch.Size([4])\n","値: Parameter containing:\n","tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","\n","層名: output.weight\n","形状: torch.Size([17, 4])\n","値: Parameter containing:\n","tensor([[-0.5327,  0.5330,  0.1805, -0.3168],\n","        [-0.1351,  0.4185,  0.2909, -0.2155],\n","        [ 0.4060, -0.0963,  0.1023, -0.0861],\n","        [ 0.3506,  0.0601,  0.4330,  0.4386],\n","        [ 0.4460,  0.0974,  0.5248,  0.3769],\n","        [ 0.4426,  0.4186, -0.0706,  0.2005],\n","        [-0.3859, -0.4978,  0.2339, -0.1157],\n","        [ 0.1178, -0.2412, -0.5000,  0.5077],\n","        [-0.0605,  0.0348, -0.3636, -0.1524],\n","        [-0.2073, -0.5180,  0.0051, -0.1845],\n","        [-0.1907, -0.2391, -0.1714,  0.3828],\n","        [ 0.1539, -0.0520, -0.3032, -0.2887],\n","        [ 0.0667,  0.2524, -0.4399, -0.4948],\n","        [ 0.3917, -0.1994, -0.4576, -0.0401],\n","        [ 0.4078,  0.2407,  0.1215,  0.3045],\n","        [ 0.4957,  0.2915,  0.4109, -0.0620],\n","        [ 0.1985,  0.2835,  0.0700,  0.0852]], device='cuda:0', requires_grad=True)\n","\n","層名: output.bias\n","形状: torch.Size([17])\n","値: Parameter containing:\n","tensor([ 0.0504, -0.2725, -0.4852, -0.1608, -0.4695, -0.4908, -0.3572,  0.4463,  0.1899, -0.0756,\n","         0.3408,  0.4059, -0.2792, -0.3925, -0.3053,  0.0007, -0.0695], device='cuda:0',\n","       requires_grad=True)\n"]}],"source":["# モデル内の層の名前とパラメータ情報を表示\n","LP = list(model.named_parameters())\n","lp = len(LP)\n","print(f\"{lp} 層\")\n","for p in range(0, lp):\n","    print(f\"\\n層名: {LP[p][0]}\")\n","    print(f\"形状: {LP[p][1].shape}\")\n","    print(f\"値: {LP[p][1]}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## 学習実行"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/625 [00:00<?, ?it/s]/home/arifuku/ymmtlab/TransformerAnsys/.venv/lib/python3.10/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n","  warnings.warn(\n","100%|██████████| 625/625 [00:08<00:00, 74.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[1/100] train loss: 2.01, valid loss: 1.29  [8s] counter: 0 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[2/100] train loss: 1.01, valid loss: 0.84  [8s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[3/100] train loss: 0.79, valid loss: 0.75  [8s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[4/100] train loss: 0.72, valid loss: 0.70  [8s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:03<00:00, 201.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[5/100] train loss: 0.68, valid loss: 0.66  [3s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:03<00:00, 201.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[6/100] train loss: 0.64, valid loss: 0.62  [3s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:03<00:00, 201.83it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[7/100] train loss: 0.60, valid loss: 0.59  [3s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:03<00:00, 201.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[8/100] train loss: 0.57, valid loss: 0.56  [3s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:03<00:00, 202.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[9/100] train loss: 0.55, valid loss: 0.55  [3s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:03<00:00, 202.21it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[10/100] train loss: 0.54, valid loss: 0.54  [3s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:03<00:00, 202.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[11/100] train loss: 0.55, valid loss: 0.53  [3s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:03<00:00, 201.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[12/100] train loss: 0.56, valid loss: 0.53  [3s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:03<00:00, 202.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[13/100] train loss: 0.54, valid loss: 0.52  [3s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:03<00:00, 201.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[14/100] train loss: 0.57, valid loss: 0.52  [3s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:03<00:00, 201.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[15/100] train loss: 0.53, valid loss: 0.52  [3s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:03<00:00, 202.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[16/100] train loss: 0.59, valid loss: 0.67  [3s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:04<00:00, 144.74it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[17/100] train loss: 0.55, valid loss: 0.52  [4s] counter: 2 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[18/100] train loss: 0.54, valid loss: 0.51  [8s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[19/100] train loss: 0.55, valid loss: 0.51  [8s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.82it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[20/100] train loss: 0.55, valid loss: 0.51  [8s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[21/100] train loss: 0.51, valid loss: 0.51  [8s] counter: 2 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[22/100] train loss: 0.55, valid loss: 0.52  [8s] counter: 3 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[23/100] train loss: 0.51, valid loss: 0.68  [8s] counter: 4 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.84it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[24/100] train loss: 0.56, valid loss: 0.62  [8s] counter: 5 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.82it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[25/100] train loss: 0.53, valid loss: 0.51  [8s] counter: 6 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[26/100] train loss: 0.51, valid loss: 0.50  [8s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[27/100] train loss: 0.54, valid loss: 0.50  [8s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.26it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[28/100] train loss: 0.53, valid loss: 0.50  [8s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[29/100] train loss: 0.50, valid loss: 0.50  [8s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[30/100] train loss: 0.50, valid loss: 0.50  [8s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[31/100] train loss: 0.53, valid loss: 0.55  [8s] counter: 2 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.30it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[32/100] train loss: 0.51, valid loss: 0.50  [8s] counter: 3 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.72it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[33/100] train loss: 0.51, valid loss: 0.50  [8s] counter: 4 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[34/100] train loss: 0.54, valid loss: 0.50  [8s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[35/100] train loss: 0.56, valid loss: 0.55  [8s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[36/100] train loss: 0.55, valid loss: 0.58  [8s] counter: 2 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[37/100] train loss: 0.56, valid loss: 0.54  [8s] counter: 3 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[38/100] train loss: 0.53, valid loss: 0.52  [8s] counter: 4 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[39/100] train loss: 0.58, valid loss: 0.56  [8s] counter: 5 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[40/100] train loss: 0.55, valid loss: 0.53  [8s] counter: 6 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[41/100] train loss: 0.52, valid loss: 0.52  [8s] counter: 7 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[42/100] train loss: 0.54, valid loss: 0.51  [8s] counter: 8 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.24it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[43/100] train loss: 0.54, valid loss: 0.50  [8s] counter: 9 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[44/100] train loss: 0.52, valid loss: 0.50  [8s] counter: 10 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[45/100] train loss: 0.50, valid loss: 0.64  [8s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[46/100] train loss: 0.52, valid loss: 0.49  [8s] counter: 2 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.73it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[47/100] train loss: 0.52, valid loss: 0.50  [8s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[48/100] train loss: 0.52, valid loss: 0.57  [8s] counter: 2 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[49/100] train loss: 0.49, valid loss: 0.49  [8s] counter: 3 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[50/100] train loss: 0.52, valid loss: 0.49  [8s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[51/100] train loss: 0.54, valid loss: 0.49  [8s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:07<00:00, 79.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[52/100] train loss: 0.52, valid loss: 0.49  [8s] counter: 2 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:07<00:00, 78.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[53/100] train loss: 0.50, valid loss: 0.49  [8s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 78.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[54/100] train loss: 0.49, valid loss: 0.48  [8s] counter: 2 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[55/100] train loss: 0.57, valid loss: 0.56  [8s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:07<00:00, 79.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[56/100] train loss: 0.55, valid loss: 0.59  [8s] counter: 2 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 75.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[57/100] train loss: 0.52, valid loss: 0.49  [8s] counter: 3 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.73it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[58/100] train loss: 0.50, valid loss: 0.48  [8s] counter: 4 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[59/100] train loss: 0.51, valid loss: 0.49  [8s] counter: 5 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[60/100] train loss: 0.52, valid loss: 0.50  [8s] counter: 6 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[61/100] train loss: 0.51, valid loss: 0.55  [8s] counter: 7 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[62/100] train loss: 0.50, valid loss: 0.56  [8s] counter: 8 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[63/100] train loss: 0.50, valid loss: 0.48  [8s] counter: 9 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[64/100] train loss: 0.49, valid loss: 0.48  [8s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:07<00:00, 79.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[65/100] train loss: 0.52, valid loss: 0.48  [8s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[66/100] train loss: 0.49, valid loss: 0.60  [8s] counter: 2 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[67/100] train loss: 0.49, valid loss: 0.48  [8s] counter: 3 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.74it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[68/100] train loss: 0.49, valid loss: 0.59  [8s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:07<00:00, 79.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[69/100] train loss: 0.50, valid loss: 0.59  [8s] counter: 2 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:07<00:00, 79.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[70/100] train loss: 0.50, valid loss: 0.48  [8s] counter: 3 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 78.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[71/100] train loss: 0.52, valid loss: 0.48  [8s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[72/100] train loss: 0.50, valid loss: 0.48  [8s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[73/100] train loss: 0.53, valid loss: 0.48  [8s] counter: 2 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[74/100] train loss: 0.53, valid loss: 0.48  [8s] counter: 3 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.21it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[75/100] train loss: 0.49, valid loss: 0.55  [8s] counter: 4 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.14it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[76/100] train loss: 0.57, valid loss: 0.57  [8s] counter: 5 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[77/100] train loss: 0.53, valid loss: 0.50  [8s] counter: 6 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[78/100] train loss: 0.50, valid loss: 0.53  [8s] counter: 7 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[79/100] train loss: 0.50, valid loss: 0.48  [8s] counter: 8 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.22it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[80/100] train loss: 0.49, valid loss: 0.50  [8s] counter: 9 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[81/100] train loss: 0.48, valid loss: 0.48  [8s] counter: 10 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[82/100] train loss: 0.48, valid loss: 0.47  [8s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[83/100] train loss: 0.50, valid loss: 0.48  [8s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[84/100] train loss: 0.48, valid loss: 0.58  [8s] counter: 2 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[85/100] train loss: 0.50, valid loss: 0.48  [8s] counter: 3 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[86/100] train loss: 0.52, valid loss: 0.63  [8s] counter: 4 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[87/100] train loss: 0.52, valid loss: 0.48  [8s] counter: 5 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.24it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[88/100] train loss: 0.49, valid loss: 0.54  [8s] counter: 6 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[89/100] train loss: 0.48, valid loss: 0.47  [8s] counter: 7 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[90/100] train loss: 0.48, valid loss: 0.47  [8s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[91/100] train loss: 0.54, valid loss: 0.50  [8s] counter: 2 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.85it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[92/100] train loss: 0.50, valid loss: 0.48  [8s] counter: 3 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[93/100] train loss: 0.51, valid loss: 0.47  [8s] counter: 4 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[94/100] train loss: 0.54, valid loss: 0.47  [8s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 77.14it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[95/100] train loss: 0.50, valid loss: 0.48  [8s] counter: 2 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:08<00:00, 76.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[96/100] train loss: 0.50, valid loss: 0.62  [8s] counter: 3 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:05<00:00, 122.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[97/100] train loss: 0.53, valid loss: 0.48  [5s] counter: 4 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:03<00:00, 200.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[98/100] train loss: 0.48, valid loss: 0.48  [3s] counter: 5 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:03<00:00, 199.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[99/100] train loss: 0.47, valid loss: 0.49  [3s] counter: 6 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:03<00:00, 201.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[100/100] train loss: 0.51, valid loss: 0.47  [3s] counter: 7 **\n"]}],"source":["epoch = 100\n","best_loss = float('Inf')\n","best_model = None\n","patience = 10\n","counter = 0\n","\n","for loop in range(1, epoch + 1):\n","    \n","    start_time = time.time()\n","    \n","    loss_train = train(\n","        model=model, data=train_iter, optimizer=optimizer,\n","        criterion=criterion, PAD_IDX=PAD_IDX\n","    )\n","    \n","    elapsed_time = time.time() - start_time\n","    \n","    loss_valid = evaluate(\n","        model=model, data=valid_iter, criterion=criterion, PAD_IDX=PAD_IDX\n","    )\n","    \n","    print('[{}/{}] train loss: {:.2f}, valid loss: {:.2f}  [{}{:.0f}s] counter: {} {}'.format(\n","        loop, epoch,\n","        loss_train, loss_valid,\n","        str(int(math.floor(elapsed_time / 60))) + 'm' if math.floor(elapsed_time / 60) > 0 else '',\n","        elapsed_time % 60,\n","        counter,\n","        '**' if best_loss > loss_valid else ''\n","    ))\n","    \n","    if best_loss > loss_valid:\n","        best_loss = loss_valid\n","        best_model = model\n","        counter = 0\n","        \n","    if counter > patience:\n","        break\n","    \n","    counter += 1"]},{"cell_type":"markdown","metadata":{},"source":["学習したモデルの保存"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["torch.save(best_model.state_dict(), model_dir_path.joinpath(version + 'translation_transfomer.pth'))"]},{"cell_type":"markdown","metadata":{},"source":["学習したモデルを使って翻訳をする"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["def translate(\n","    model, text, vocab_src, vocab_tgt, seq_len_tgt,\n","    START_IDX, END_IDX\n","):\n","    model.eval()\n","    tokens_src = convert_text_to_indexes(text, vocab=vocab_src)\n","    num_tokens_src = len(tokens_src)\n","\n","    # Tensorに変換\n","    src = torch.LongTensor(tokens_src).reshape(num_tokens_src, 1).to(device)\n","    mask_src = torch.zeros((num_tokens_src, num_tokens_src), device=device).type(torch.bool)\n","\n","    # デコード\n","    predicts = greedy_decode(\n","        model=model, src=src,\n","        mask_src=mask_src, seq_len_tgt=seq_len_tgt,\n","        START_IDX=START_IDX, END_IDX=END_IDX\n","    ).flatten()\n","\n","    return convert_indexes_to_text(predicts.tolist(), vocab=vocab_tgt)\n","\n","def greedy_decode(model, src, mask_src, seq_len_tgt, START_IDX, END_IDX):\n","    src = src.to(device)\n","    mask_src = mask_src.to(device)\n","\n","    # ソースの埋め込みをメモリとして利用\n","    memory = model.positional_encoding(model.token_embedding_src(src))\n","    \n","    ys = torch.ones(1, 1).fill_(START_IDX).type(torch.long).to(device)\n","    \n","    for i in range(seq_len_tgt - 1):\n","        memory = memory.to(device)\n","        mask_tgt = generate_square_subsequent_mask(ys.size(0)).to(device).type(torch.bool)\n","        \n","        output = model.decode(ys, memory, mask_tgt)\n","        output = output.transpose(0, 1)\n","        output = model.output(output[:, -1])\n","        \n","        # 最も高いスコアのトークンを取得\n","        _, next_word = torch.max(output, dim=1)\n","        next_word = next_word.item()\n","\n","        # 生成されたトークンを追加\n","        ys = torch.cat([ys, torch.ones(1, 1).fill_(next_word).type_as(src.data)], dim=0)\n","        if next_word == END_IDX:\n","            break\n","    \n","    return ys\n"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: - 5 2\n","Output: 5 2 -\n"]}],"source":["seq_len_tgt = max([len(x[1]) for x in train_data])\n","text = '- 5 2'\n","\n","# 翻訳を実行\n","translation = translate(\n","    model=best_model, text=text, vocab_src=vocab_src, vocab_tgt=vocab_tgt,\n","    seq_len_tgt=seq_len_tgt,\n","    START_IDX=START_IDX, END_IDX=END_IDX\n",")\n","\n","print(f\"Input: {text}\")\n","print(f\"Output: {translation}\")"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: - 2 7\n","Output: 2 7 -\n","Target: 2 7 -\n","---\n","Input: - 9 7\n","Output: 9 7 -\n","Target: 9 7 -\n","---\n","Input: + - 2 7 4\n","Output: 6 5 + 3 +\n","Target: 2 7 - 4 +\n","---\n","Input: - - 6 9 - 7 3\n","Output: 4 6 - 3 - - 3 - - -\n","Target: 6 9 - 7 3 - -\n","---\n","Input: - - + + + + + 4 6 3 7 + 6 7 1 9 + + 3 6 2\n","Output: 6 6 4 + + 3 + + 4 + + + + 9 + + 4 + + 4 + + 9 + + + + + + + + + + + + \n","Target: 4 6 + 3 + 7 + 6 7 + + 1 + 9 - 3 6 + 2 + - \n","---\n"]}],"source":["# 様々な入力を試してみる\n","\n","text_list = { '- 2 7':'2 7 -', '- 9 7' : '9 7 -', '+ - 2 7 4' : '2 7 - 4 +', '- - 6 9 - 7 3' : '6 9 - 7 3 - -', '- - + + + + + 4 6 3 7 + 6 7 1 9 + + 3 6 2' : '4 6 + 3 + 7 + 6 7 + + 1 + 9 - 3 6 + 2 + - '}\n","\n","for text, tgt in text_list.items():\n","    translation = translate(\n","        model=best_model, text=text, vocab_src=vocab_src, vocab_tgt=vocab_tgt,\n","        seq_len_tgt=seq_len_tgt,\n","        START_IDX=START_IDX, END_IDX=END_IDX\n","    )\n","    print(f\"Input: {text}\")\n","    print(f\"Output: {translation}\")\n","    print(f\"Target: {tgt}\")\n","    print('---')\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## モデルの動作を分析"]},{"cell_type":"code","execution_count":126,"metadata":{},"outputs":[{"data":{"text/plain":["Seq2SeqTransformer(\n","  (token_embedding_src): TokenEmbedding(\n","    (embedding): Embedding(17, 4, padding_idx=11)\n","  )\n","  (positional_encoding): PositionalEncoding(\n","    (dropout): Dropout(p=0, inplace=False)\n","  )\n","  (token_embedding_tgt): TokenEmbedding(\n","    (embedding): Embedding(17, 4, padding_idx=11)\n","  )\n","  (decoder_layer): TransformerDecoderLayerScratch(\n","    (self_attn): MultiheadAttention(\n","      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n","    )\n","    (multihead_attn): MultiheadAttention(\n","      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n","    )\n","    (linear1): Linear(in_features=4, out_features=4, bias=True)\n","    (dropout): Dropout(p=0, inplace=False)\n","    (linear2): Linear(in_features=4, out_features=4, bias=True)\n","    (norm1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n","    (norm2): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n","    (norm3): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n","    (dropout1): Dropout(p=0, inplace=False)\n","    (dropout2): Dropout(p=0, inplace=False)\n","    (dropout3): Dropout(p=0, inplace=False)\n","  )\n","  (output): Linear(in_features=4, out_features=17, bias=True)\n",")"]},"execution_count":126,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","\n","# モデルのロード\n","model_path = model_dir_path.joinpath(version + 'translation_transfomer.pth')\n","loaded_model = Seq2SeqTransformer(\n","    num_encoder_layers=num_encoder_layers,\n","    num_decoder_layers=num_decoder_layers,\n","    embedding_size=embedding_size,\n","    vocab_size_src=vocab_size_src, vocab_size_tgt=vocab_size_tgt,\n","    dim_feedforward=dim_feedforward,\n","    dropout=dropout, nhead=nhead\n",").to(device)\n","loaded_model.load_state_dict(torch.load(model_path))\n","loaded_model.eval()\n"]},{"cell_type":"code","execution_count":127,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["dict_keys(['token_embedding_src.embedding.weight', 'token_embedding_tgt.embedding.weight', 'decoder_layer.self_attn.in_proj_weight', 'decoder_layer.self_attn.in_proj_bias', 'decoder_layer.self_attn.out_proj.weight', 'decoder_layer.self_attn.out_proj.bias', 'decoder_layer.multihead_attn.in_proj_weight', 'decoder_layer.multihead_attn.in_proj_bias', 'decoder_layer.multihead_attn.out_proj.weight', 'decoder_layer.multihead_attn.out_proj.bias', 'decoder_layer.linear1.weight', 'decoder_layer.linear1.bias', 'decoder_layer.linear2.weight', 'decoder_layer.linear2.bias', 'decoder_layer.norm1.weight', 'decoder_layer.norm1.bias', 'decoder_layer.norm2.weight', 'decoder_layer.norm2.bias', 'decoder_layer.norm3.weight', 'decoder_layer.norm3.bias', 'output.weight', 'output.bias'])\n"]}],"source":["# パラメータを取り出す\n","\n","\n","# モデルのパラメータを取得\n","params = dict(loaded_model.named_parameters())\n","print(params.keys())\n","\n","# 埋め込み行列を取得\n","embedding_src_weight = params['token_embedding_src.embedding.weight'].data\n","embedding_tgt_weight = params['token_embedding_tgt.embedding.weight'].data\n","\n","# 線形層の重みとバイアス\n","output_weight = params['output.weight'].data\n","output_bias = params['output.bias'].data\n","\n","# デコーダの自己注意の重みとバイアス\n","self_attn_in_proj_weight = params['decoder_layer.self_attn.in_proj_weight'].data\n","self_attn_in_proj_bias = params['decoder_layer.self_attn.in_proj_bias'].data\n","self_attn_out_proj_weight = params['decoder_layer.self_attn.out_proj.weight'].data\n","self_attn_out_proj_bias = params['decoder_layer.self_attn.out_proj.bias'].data\n","\n","# メモリー注意の重みとバイアス\n","multihead_attn_in_proj_weight = params['decoder_layer.multihead_attn.in_proj_weight'].data\n","multihead_attn_in_proj_bias = params['decoder_layer.multihead_attn.in_proj_bias'].data\n","multihead_attn_out_proj_weight = params['decoder_layer.multihead_attn.out_proj.weight'].data\n","multihead_attn_out_proj_bias = params['decoder_layer.multihead_attn.out_proj.bias'].data\n","\n","# フィードフォワードネットワークの重みとバイアス\n","linear1_weight = params['decoder_layer.linear1.weight'].data\n","linear1_bias = params['decoder_layer.linear1.bias'].data\n","linear2_weight = params['decoder_layer.linear2.weight'].data\n","linear2_bias = params['decoder_layer.linear2.bias'].data\n","\n","# LayerNormのパラメータ\n","norm1_weight = params['decoder_layer.norm1.weight'].data\n","norm1_bias = params['decoder_layer.norm1.bias'].data\n","norm2_weight = params['decoder_layer.norm2.weight'].data\n","norm2_bias = params['decoder_layer.norm2.bias'].data\n","norm3_weight = params['decoder_layer.norm3.weight'].data\n","norm3_bias = params['decoder_layer.norm3.bias'].data\n"]},{"cell_type":"code","execution_count":128,"metadata":{},"outputs":[],"source":["\n","# Positional Encoding\n","def positional_encoding(tensor: Tensor, maxlen=5000):\n","    embedding_size = tensor.size(-1)\n","    den = torch.exp(-torch.arange(0, embedding_size, 2) * math.log(10000) / embedding_size)\n","    pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n","    embedding_pos = torch.zeros((maxlen, embedding_size))\n","    embedding_pos[:, 0::2] = torch.sin(pos * den)\n","    embedding_pos[:, 1::2] = torch.cos(pos * den)\n","    embedding_pos = embedding_pos.unsqueeze(-2)\n","    return tensor + embedding_pos[: tensor.size(0), :].to(tensor.device)"]},{"cell_type":"code","execution_count":203,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["3\n","14\n","1\n","14\n","15\n","13\n","Input: + 3 1\n","Decoded sequence: 3 1 +\n"]}],"source":["\n","# 翻訳処理を実行\n","seq_len_tgt = max([len(x[1]) for x in train_data])\n","text = '+ 3 1'\n","\n","tokens_src = convert_text_to_indexes(text, vocab=vocab_src)\n","src = torch.LongTensor(tokens_src).reshape(len(tokens_src), 1).to(device)\n","memory = positional_encoding(embedding_src_weight[src] * math.sqrt(embedding_size))\n","ys = torch.ones(1, 1).fill_(START_IDX).type(torch.long).to(device)\n","\n","for i in range(10):\n","    tgt_embed = positional_encoding(embedding_tgt_weight[ys] * math.sqrt(embedding_size))\n","    tgt_mask = generate_square_subsequent_mask(ys.size(0)).to(device).type(torch.bool)\n","    \n","    # Self-attention\n","    self_attn_wq, self_attn_wk, self_attn_wv = self_attn_in_proj_weight.chunk(3, dim=0)\n","    self_attn_bq, self_attn_bk, self_attn_bv = self_attn_in_proj_bias.chunk(3, dim=0)\n","    QW = torch.matmul(tgt_embed.permute(1, 0, 2), self_attn_wq.T) + self_attn_bq\n","    KW = torch.matmul(tgt_embed.permute(1, 0, 2), self_attn_wk.T) + self_attn_bk\n","    VW = torch.matmul(tgt_embed.permute(1, 0, 2), self_attn_wv.T) + self_attn_bv\n","    self_attn_weights = F.softmax(torch.bmm(QW, KW.transpose(-2, -1)) / math.sqrt(embedding_size), dim=-1)\n","\n","    AV = torch.matmul(self_attn_weights, VW)\n","    self_attn_output = torch.matmul(AV, self_attn_out_proj_weight.T) + self_attn_out_proj_bias\n","    self_attn_output = self_attn_output.permute(1, 0, 2)\n","    tgt = tgt_embed + self_attn_output\n","    tgt = loaded_model.decoder_layer.norm1(tgt)\n","\n","\n","\n","    # Attention with the encoder outputs (memory)\n","    multi_attn_wq, multi_attn_wk, multi_attn_wv = multihead_attn_in_proj_weight.chunk(3, dim=0)\n","    multi_attn_bq, multi_attn_bk, multi_attn_bv = multihead_attn_in_proj_bias.chunk(3, dim=0)\n","    QW = torch.matmul(tgt.permute(1, 0, 2), multi_attn_wq.T) + multi_attn_bq\n","    KW = torch.matmul(memory.permute(1, 0, 2), multi_attn_wk.T) + multi_attn_bk\n","    VW = torch.matmul(memory.permute(1, 0, 2), multi_attn_wv.T) + multi_attn_bv\n","    multi_attn_weights = F.softmax(torch.bmm(QW, KW.transpose(-2, -1)) / math.sqrt(embedding_size), dim=-1)\n","\n","    AV = torch.matmul(multi_attn_weights, VW)\n","    multi_attn_output = torch.matmul(AV, multihead_attn_out_proj_weight.T) + multihead_attn_out_proj_bias\n","    multi_attn_output = multi_attn_output.permute(1, 0, 2)\n","    tgt = tgt + multi_attn_output\n","    tgt = loaded_model.decoder_layer.norm2(tgt)\n","    \n","    # Feedforward network\n","\n","    # decoder linear1, 2\n","    tgt2 = tgt.matmul(linear1_weight.T) + linear1_bias\n","    tgt2 = F.relu(tgt2)\n","    tgt2 = tgt2.matmul(linear2_weight.T) + linear2_bias\n","    tgt = tgt + tgt2\n","\n","    # LayerNorm\n","    tgt = loaded_model.decoder_layer.norm3(tgt)\n","\n","    output = tgt.transpose(0, 1)\n","    output = loaded_model.output(output[:, -1])\n","\n","    _, next_word = torch.max(output, dim=1)\n","    next_word = next_word.item()\n","\n","    ys = torch.cat([ys, torch.ones(1, 1).fill_(next_word).type_as(src.data)], dim=0)\n","    print(next_word)\n","    \n","    if next_word == END_IDX:\n","        break\n","\n","\n","flat_indexes = [idx for sublist in ys.tolist() for idx in sublist] if isinstance(ys.tolist()[0], list) else ys.tolist()\n","\n","print(f\"Input: {text}\")\n","print(f\"Decoded sequence: {convert_indexes_to_text(flat_indexes, vocab_tgt)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Transformerの検算\n","\n","スクラッチで書くための検算\n","\n","## Multihead Attention\n","\n","Multihead Attentionの動作をスクラッチで書きたいので、ここで検算する\n","\n","参考サイト\n","https://blog.amedama.jp/entry/pytorch-multi-head-attention-verify"]},{"cell_type":"code","execution_count":161,"metadata":{},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n"]},{"cell_type":"code","execution_count":168,"metadata":{},"outputs":[],"source":["edim = 4 # 埋め込み次元\n","num_heads = 1 # ヘッド数\n","model = nn.MultiheadAttention(edim, num_heads, bias=True)"]},{"cell_type":"code","execution_count":176,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X: torch.Size([1, 1, 4])\n","Y: torch.Size([7, 1, 4])\n"]}],"source":["batch_size = 1\n","L=5\n","X = torch.randn(batch_size, 1, edim) # 入力\n","Y = torch.randn(7, 1, edim) # 出力\n","print(\"X:\", X.shape)\n","print(\"Y:\", Y.shape)"]},{"cell_type":"code","execution_count":178,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 1, 4])\n","tensor([[[-0.3499, -0.2916, -0.3890, -0.2463]]], grad_fn=<ViewBackward0>)\n","tensor([[[0.1734, 0.1847, 0.1077, 0.1364, 0.2069, 0.1434, 0.0475]]], grad_fn=<MeanBackward1>)\n"]}],"source":["attn_output, attn_output_weights = model(X, Y, Y)\n","\n","print(attn_output.shape)\n","print(attn_output)\n","print(attn_output_weights)"]},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[('in_proj_weight',\n","  Parameter containing:\n","tensor([[-0.5630, -0.2601, -0.1945, -0.5896],\n","        [-0.4404, -0.4852,  0.0115, -0.5999],\n","        [-0.1480, -0.3680,  0.5783,  0.3258],\n","        [ 0.1237,  0.1261,  0.5127,  0.4791],\n","        [-0.5049, -0.2961,  0.1912,  0.4764],\n","        [ 0.0325, -0.2752, -0.3576, -0.1833],\n","        [ 0.4593, -0.1369, -0.0845, -0.2567],\n","        [-0.4142, -0.3853,  0.3486, -0.1582],\n","        [ 0.1128, -0.1040, -0.0759, -0.5081],\n","        [-0.5086, -0.5566,  0.2522, -0.4853],\n","        [ 0.3230, -0.1686,  0.4186,  0.3168],\n","        [-0.0464,  0.4538,  0.1423, -0.0617]], requires_grad=True)),\n"," ('in_proj_bias',\n","  Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n"," ('out_proj.weight',\n","  Parameter containing:\n","tensor([[-0.4730,  0.0490, -0.0549,  0.3015],\n","        [-0.4261,  0.2245, -0.0424,  0.2772],\n","        [ 0.3448,  0.4979, -0.0949,  0.0385],\n","        [-0.4854,  0.3669,  0.0725, -0.3572]], requires_grad=True)),\n"," ('out_proj.bias',\n","  Parameter containing:\n","tensor([0., 0., 0., 0.], requires_grad=True))]\n"]}],"source":["from pprint import pprint\n","pprint(list(model.named_parameters()))"]},{"cell_type":"code","execution_count":175,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-0.5808, -0.1098, -0.0357, -0.5751],\n","        [-0.0407,  0.0463, -0.6055, -0.3367],\n","        [ 0.0830, -0.4848, -0.0125,  0.0392],\n","        [-0.2178, -0.2547, -0.5971, -0.3331],\n","        [ 0.0095, -0.2803, -0.5334,  0.2403],\n","        [-0.4390,  0.5532, -0.5252,  0.1394],\n","        [-0.0308, -0.3543, -0.5856, -0.3669],\n","        [ 0.3372,  0.3948, -0.2288, -0.4667],\n","        [ 0.4484,  0.5747,  0.4883, -0.0618],\n","        [ 0.2787,  0.2623,  0.2026,  0.1039],\n","        [ 0.1447, -0.0516,  0.3138, -0.0649],\n","        [-0.3639,  0.1680,  0.5810,  0.5685]])\n"]}],"source":["model_weight = {name: param.data for name, param in model.named_parameters()}\n","Wi = model_weight['in_proj_weight']\n","Wo = model_weight['out_proj.weight']\n","Wbi = model_weight['in_proj_bias']\n","Wbo = model_weight['out_proj.bias']\n","print(Wi)"]},{"cell_type":"code","execution_count":181,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 1, 4])\n","tensor([[[ 1.6785,  0.1756, -0.3511,  0.2078]]])\n"]}],"source":["Wi_q, Wi_k, Wi_v = Wi.chunk(3, dim=0)\n","Wbi_q, Wbi_k, Wbi_v = Wbi.chunk(3, dim=0)\n","QW = torch.matmul(X.permute(1, 0, 2), Wi_q.T) + Wbi_q\n","KW = torch.matmul(Y.permute(1, 0, 2), Wi_k.T) + Wbi_k\n","VW = torch.matmul(Y.permute(1, 0, 2), Wi_v.T) + Wbi_v\n","\n","print(QW.shape)\n","print(QW)\n","\n","KW_t = KW.transpose(-2, -1)\n","QK_t = torch.bmm(QW, KW_t)\n","QK_scaled = QK_t / (edim ** 0.5)\n","attn_weights_ = F.softmax(QK_scaled, dim=-1)"]},{"cell_type":"code","execution_count":174,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[0.1296, 0.1531, 0.1393, 0.1467, 0.1635, 0.1132, 0.1546]]])\n","tensor([[[0.1296, 0.1531, 0.1393, 0.1467, 0.1635, 0.1132, 0.1546]]], grad_fn=<MeanBackward1>)\n"]}],"source":["print(attn_weights_)\n","print(attn_output_weights)"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["AV = torch.matmul(attn_weights_, VW)\n","attn_output_ = torch.matmul(AV, Wo.T) + Wbo"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[-0.0625,  0.0904,  0.1305, -0.1482],\n","         [-0.4081,  0.3104,  0.2189, -0.0764],\n","         [-0.4028,  0.3015,  0.2174, -0.0791],\n","         [-0.3206,  0.2504,  0.1944, -0.0949],\n","         [-0.1308,  0.1265,  0.1498, -0.1374]],\n","\n","        [[-0.1675,  0.1690,  0.1499, -0.0520],\n","         [-0.1171,  0.0575,  0.0756, -0.0196],\n","         [-0.1866,  0.1673,  0.1616, -0.0732],\n","         [-0.1517,  0.1413,  0.1286, -0.0436],\n","         [-0.1326,  0.0947,  0.1009, -0.0316]]])\n","tensor([[[-0.0625,  0.0904,  0.1305, -0.1482],\n","         [-0.4081,  0.3104,  0.2189, -0.0764],\n","         [-0.4028,  0.3015,  0.2174, -0.0791],\n","         [-0.3206,  0.2504,  0.1944, -0.0949],\n","         [-0.1308,  0.1265,  0.1498, -0.1374]],\n","\n","        [[-0.1675,  0.1690,  0.1499, -0.0520],\n","         [-0.1171,  0.0575,  0.0756, -0.0196],\n","         [-0.1866,  0.1673,  0.1616, -0.0732],\n","         [-0.1517,  0.1413,  0.1286, -0.0436],\n","         [-0.1326,  0.0947,  0.1009, -0.0316]]], grad_fn=<TransposeBackward0>)\n"]}],"source":["print(attn_output_)\n","print(attn_output)"]},{"cell_type":"markdown","metadata":{},"source":["## nn.Linear"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":["Linear(in_features=4, out_features=4, bias=True)"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["model = nn.Linear(4, 4)\n","model"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[('weight',\n","  Parameter containing:\n","tensor([[ 0.4057, -0.1641, -0.1456,  0.2699],\n","        [-0.2218, -0.0159, -0.4409,  0.1662],\n","        [ 0.3244,  0.2228, -0.1661, -0.1230],\n","        [-0.1333,  0.3326, -0.3842, -0.0652]], requires_grad=True)),\n"," ('bias',\n","  Parameter containing:\n","tensor([-0.1197,  0.4730,  0.3838, -0.2536], requires_grad=True))]\n"]}],"source":["pprint(list(model.named_parameters()))"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([4])\n","tensor([-0.3750,  0.0861, -1.5094, -0.3185])\n","torch.Size([4])\n","tensor([-0.1522,  1.1674,  0.5712,  0.4257], grad_fn=<ViewBackward0>)\n"]}],"source":["model_weight = {name: param.data for name, param in model.named_parameters()}\n","W = model_weight['weight']\n","B = model_weight['bias']\n","\n","X = torch.randn(4) \n","print(X.shape)\n","print(X)\n","output = model(X)\n","print(output.shape)\n","print(output)\n"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([-0.1522,  1.1674,  0.5712,  0.4257])\n","tensor([-0.1522,  1.1674,  0.5712,  0.4257], grad_fn=<ViewBackward0>)\n"]}],"source":["output_ = X.matmul(W.T) + B\n","print(output_)\n","print(output)"]},{"cell_type":"markdown","metadata":{},"source":["## nn.LayerNorm\n","\n","参考サイト\n","https://qiita.com/dl_from_scratch/items/133fe741b67ed14f1856"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/plain":["LayerNorm((4,), eps=1e-05, elementwise_affine=True)"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["model = nn.LayerNorm(4)\n","model"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[('weight', Parameter containing:\n","tensor([1., 1., 1., 1.], requires_grad=True)),\n"," ('bias', Parameter containing:\n","tensor([0., 0., 0., 0.], requires_grad=True))]\n"]}],"source":["pprint(list(model.named_parameters()))"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([4])\n","tensor([ 0.2881, -0.5361,  1.9212, -0.8353])\n","torch.Size([4])\n","tensor([ 0.0734, -0.6965,  1.5990, -0.9760], grad_fn=<NativeLayerNormBackward0>)\n"]}],"source":["model_weight = {name: param.data for name, param in model.named_parameters()}\n","W = model_weight['weight']\n","B = model_weight['bias']\n","\n","X = torch.randn(4) \n","print(X.shape)\n","print(X)\n","output = model(X)\n","print(output.shape)\n","print(output)\n"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0.8379, 0.8379, 0.8379, 0.8379])\n","tensor([ 0.0734, -0.6965,  1.5990, -0.9760], grad_fn=<NativeLayerNormBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_168480/3362812588.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3675.)\n","  output_ = X.matmul(W.T) + B\n"]}],"source":["output_ = X.matmul(W.T) + B\n","print(output_)\n","print(output)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"KantaiBERT_2.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
