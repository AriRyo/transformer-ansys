{"cells":[{"cell_type":"markdown","metadata":{"id":"M1oqh0F6W3ad"},"source":["# FomulaBEAT\n","\n","変更点\n","- PyTorchの公式サイトをもとにTransformerのコードを作り変える\n","    - 参考サイト: https://pytorch.org/tutorials/beginner/translation_transformer.html\n","    - 参考サイト2: https://www.dskomei.com/entry/2021/05/24/165158\n"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["version = '02'\n","model_dir = './model/' + version\n","data_path = 'data/eq02.txt'\n"]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2860,"status":"ok","timestamp":1611303247694,"user":{"displayName":"Karan Sonawane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWjX1_4b0iu2fEkjbIRKIHq-Molc5N_CnbcU75=s64","userId":"05479461208077736330"},"user_tz":-330},"id":"IMnymRDLe0hi","outputId":"706de1c8-715a-41e2-bdcf-3caa67125bf8"},"outputs":[],"source":["from pathlib import Path\n","import math\n","import time\n","from collections import Counter\n","from tqdm import tqdm\n","import torch\n","from torch.utils.data import random_split\n","import torch.nn as nn\n","from torch import Tensor\n","from torch.nn import (\n","    TransformerEncoder, TransformerDecoder,\n","    TransformerEncoderLayer, TransformerDecoderLayer\n",")\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import vocab\n","from torchtext.utils import download_from_url, extract_archive"]},{"cell_type":"markdown","metadata":{},"source":["パラメータの事前設定"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["%load_ext autoreload\n","%autoreload 2\n","torch.set_printoptions(linewidth=100)"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","model_dir_path = Path(model_dir)\n","if not model_dir_path.exists():\n","    model_dir_path.mkdir(parents=True)"]},{"cell_type":"markdown","metadata":{},"source":["データの取得"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["def read_equation_file(file_path):\n","    with open(file_path, 'r') as file:\n","        lines = file.readlines()\n","    src_data, tgt_data = [], []\n","    for line in lines:\n","        src, tgt = line.strip().split('=')\n","        src_data.append(src)\n","        tgt_data.append(tgt)\n","    return src_data, tgt_data\n"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['8+0', '5+2', '5+1'] ['8', '7', '6']\n"]}],"source":["# ファイルを読み込み、数式データを取得\n","src_data, tgt_data = read_equation_file(data_path)\n","print(src_data[:3], tgt_data[:3])\n"]},{"cell_type":"markdown","metadata":{},"source":["# 辞書データの作成"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":["\n","SPECIALS = ['<unk>', '<pad>', '<start>', '<end>']\n","\n","def build_vocab(texts):\n","    vocab = {}\n","    idx = 0\n","    # 数字の語彙定義\n","    for i in range(10):\n","        vocab[str(i)] = idx\n","        idx += 1\n","    # 特別語の語彙定義\n","    for sp in SPECIALS:\n","        vocab[sp] = idx\n","        idx += 1\n","    # その他の文字の語彙定義\n","    for text in texts:\n","        for char in text:\n","            if char not in vocab:\n","                vocab[char] = idx\n","                idx += 1\n","    return vocab\n","\n","\n","def convert_text_to_indexes(text, vocab):\n","    # <start> と <end> トークンを追加して数値化\n","    return [vocab['<start>']] + [vocab[char] if char in vocab else vocab['<unk>'] for char in text] + [vocab['<end>']]\n","\n","# データを処理して Train と Valid に分ける関数\n","# データを処理して Train と Valid に分ける関数\n","def data_process_split(src_texts, tgt_texts, vocab_src, vocab_tgt, valid_size=0.2):\n","    # データを数値化\n","    data = []\n","    for (src, tgt) in zip(src_texts, tgt_texts):\n","        src_tensor = torch.tensor(convert_text_to_indexes(src, vocab_src), dtype=torch.long)\n","        tgt_tensor = torch.tensor(convert_text_to_indexes(tgt, vocab_tgt), dtype=torch.long)\n","        data.append((src_tensor, tgt_tensor))\n","    \n","    # データのサイズを計算して、訓練データと検証データに分割\n","    data_size = len(data)\n","    valid_size = int(valid_size * data_size)\n","    train_size = data_size - valid_size\n","\n","    # PyTorchのrandom_splitを使って分割\n","    train_data, valid_data = random_split(data, [train_size, valid_size])\n","    \n","    return train_data, valid_data\n","\n"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '<unk>': 10, '<pad>': 11, '<start>': 12, '<end>': 13}\n"]}],"source":["# 辞書と逆辞書を構築\n","vocab_src = build_vocab(src_data)\n","vocab_tgt = build_vocab(tgt_data)\n","\n","print(vocab_tgt)"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["インデックス化された文章\n","Input: tensor([12,  5, 14,  1, 13])\n","Output: tensor([12,  6, 13])\n","元に戻した文章\n","Input: 5+1\n","Output: 6\n"]}],"source":["\n","# データを数値化\n","train_data, valid_data = data_process_split(src_data, tgt_data, vocab_src, vocab_tgt)\n","\n","# 結果の確認\n","print('インデックス化された文章')\n","print(f\"Input: {train_data[0][0]}\\nOutput: {train_data[0][1]}\")\n","\n","# インデックスから元の文字列に戻す\n","def convert_indexes_to_text(indexes, vocab):\n","    reverse_vocab = {idx: token for token, idx in vocab.items()}\n","    indexes = indexes.tolist()\n","    return ''.join([reverse_vocab[idx] for idx in indexes if idx in reverse_vocab and reverse_vocab[idx] not in ['<start>', '<end>', '<pad>']])\n","\n","print('元に戻した文章')\n","print(f\"Input: {convert_indexes_to_text(train_data[0][0], vocab_src)}\")\n","print(f\"Output: {convert_indexes_to_text(train_data[0][1], vocab_tgt)}\")\n"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[],"source":["batch_size = 128\n","PAD_IDX = vocab_src['<pad>']\n","START_IDX = vocab_src['<start>']\n","END_IDX = vocab_src['<end>']\n","\n","def generate_batch(data_batch):\n","    \n","    batch_src, batch_tgt = [], []\n","    for src, tgt in data_batch:\n","        batch_src.append(src)\n","        batch_tgt.append(tgt)\n","        \n","    batch_src = pad_sequence(batch_src, padding_value=PAD_IDX)\n","    batch_tgt = pad_sequence(batch_tgt, padding_value=PAD_IDX)\n","    \n","    return batch_src, batch_tgt\n","\n","train_iter = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=generate_batch)\n","valid_iter = DataLoader(valid_data, batch_size=batch_size, shuffle=True, collate_fn=generate_batch)"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"data":{"text/plain":["8000"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["len(train_data)"]},{"cell_type":"markdown","metadata":{},"source":["Transoformerの設定"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":["class TokenEmbedding(nn.Module):\n","    \n","    def __init__(self, vocab_size, embedding_size):\n","        \n","        super(TokenEmbedding, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_size)\n","        self.embedding_size = embedding_size\n","        \n","    def forward(self, tokens: Tensor):\n","        return self.embedding(tokens.long()) * math.sqrt(self.embedding_size)\n","    \n","    \n","class PositionalEncoding(nn.Module):\n","    \n","    def __init__(self, embedding_size: int, dropout: float, maxlen: int = 5000):\n","        super(PositionalEncoding, self).__init__()\n","        \n","        den = torch.exp(-torch.arange(0, embedding_size, 2) * math.log(10000) / embedding_size)\n","        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n","        embedding_pos = torch.zeros((maxlen, embedding_size))\n","        embedding_pos[:, 0::2] = torch.sin(pos * den)\n","        embedding_pos[:, 1::2] = torch.cos(pos * den)\n","        embedding_pos = embedding_pos.unsqueeze(-2)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer('embedding_pos', embedding_pos)\n","\n","    def forward(self, token_embedding: Tensor):\n","        return self.dropout(token_embedding + self.embedding_pos[: token_embedding.size(0), :])\n"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[],"source":["class Seq2SeqTransformer(nn.Module):\n","    \n","    def __init__(\n","        self, num_encoder_layers: int, num_decoder_layers: int,\n","        embedding_size: int, vocab_size_src: int, vocab_size_tgt: int,\n","        dim_feedforward:int = 512, dropout:float = 0.1, nhead:int = 8\n","    ):\n","        \n","        super(Seq2SeqTransformer, self).__init__()\n","\n","        self.token_embedding_src = TokenEmbedding(vocab_size_src, embedding_size)\n","        self.positional_encoding = PositionalEncoding(embedding_size, dropout=dropout)\n","        encoder_layer = TransformerEncoderLayer(\n","            d_model=embedding_size, nhead=nhead, dim_feedforward=dim_feedforward\n","        )\n","        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n","        \n","        self.token_embedding_tgt = TokenEmbedding(vocab_size_tgt, embedding_size)\n","        decoder_layer = TransformerDecoderLayer(\n","            d_model=embedding_size, nhead=nhead, dim_feedforward=dim_feedforward\n","        )\n","        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n","        \n","        self.output = nn.Linear(embedding_size, vocab_size_tgt)\n","\n","    def forward(\n","        self, src: Tensor, tgt: Tensor,\n","        mask_src: Tensor, mask_tgt: Tensor,\n","        padding_mask_src: Tensor, padding_mask_tgt: Tensor,\n","        memory_key_padding_mask: Tensor\n","    ):\n","        \n","        embedding_src = self.positional_encoding(self.token_embedding_src(src))\n","        memory = self.transformer_encoder(embedding_src, mask_src, padding_mask_src)\n","        embedding_tgt = self.positional_encoding(self.token_embedding_tgt(tgt))\n","        outs = self.transformer_decoder(\n","            embedding_tgt, memory, mask_tgt, None,\n","            padding_mask_tgt, memory_key_padding_mask\n","        )\n","        return self.output(outs)\n","\n","    def encode(self, src: Tensor, mask_src: Tensor):\n","        return self.transformer_encoder(self.positional_encoding(self.token_embedding_src(src)), mask_src)\n","\n","    def decode(self, tgt: Tensor, memory: Tensor, mask_tgt: Tensor):\n","        return self.transformer_decoder(self.positional_encoding(self.token_embedding_tgt(tgt)), memory, mask_tgt)"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[],"source":["def create_mask(src, tgt, PAD_IDX):\n","    \n","    seq_len_src = src.shape[0]\n","    seq_len_tgt = tgt.shape[0]\n","\n","    mask_src = torch.zeros((seq_len_src, seq_len_src), device=device).type(torch.bool)\n","    mask_tgt = generate_square_subsequent_mask(seq_len_tgt)\n","\n","    padding_mask_src = (src == PAD_IDX).transpose(0, 1)\n","    padding_mask_tgt = (tgt == PAD_IDX).transpose(0, 1)\n","    \n","    return mask_src, mask_tgt, padding_mask_src, padding_mask_tgt\n","\n","\n","def generate_square_subsequent_mask(seq_len):\n","    mask = (torch.triu(torch.ones((seq_len, seq_len), device=device)) == 1).transpose(0, 1)\n","    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","    return mask"]},{"cell_type":"markdown","metadata":{},"source":["Transfomerを学習させる"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[],"source":["def train(model, data, optimizer, criterion, PAD_IDX):\n","    \n","    model.train()\n","    losses = 0\n","    for src, tgt in tqdm(data):\n","        \n","        src = src.to(device)\n","        tgt = tgt.to(device)\n","\n","        input_tgt = tgt[:-1, :]\n","\n","        mask_src, mask_tgt, padding_mask_src, padding_mask_tgt = create_mask(src, input_tgt, PAD_IDX)\n","\n","        logits = model(\n","            src=src, tgt=input_tgt,\n","            mask_src=mask_src, mask_tgt=mask_tgt,\n","            padding_mask_src=padding_mask_src, padding_mask_tgt=padding_mask_tgt,\n","            memory_key_padding_mask=padding_mask_src\n","        )\n","\n","        optimizer.zero_grad()\n","\n","        output_tgt = tgt[1:, :]\n","        loss = criterion(logits.reshape(-1, logits.shape[-1]), output_tgt.reshape(-1))\n","        loss.backward()\n","\n","        optimizer.step()\n","        losses += loss.item()\n","        \n","    return losses / len(data)"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[],"source":["def evaluate(model, data, criterion, PAD_IDX):\n","    \n","    model.eval()\n","    losses = 0\n","    for src, tgt in data:\n","        \n","        src = src.to(device)\n","        tgt = tgt.to(device)\n","\n","        input_tgt = tgt[:-1, :]\n","\n","        mask_src, mask_tgt, padding_mask_src, padding_mask_tgt = create_mask(src, input_tgt, PAD_IDX)\n","\n","        logits = model(\n","            src=src, tgt=input_tgt,\n","            mask_src=mask_src, mask_tgt=mask_tgt,\n","            padding_mask_src=padding_mask_src, padding_mask_tgt=padding_mask_tgt,\n","            memory_key_padding_mask=padding_mask_src\n","        )\n","        \n","        output_tgt = tgt[1:, :]\n","        loss = criterion(logits.reshape(-1, logits.shape[-1]), output_tgt.reshape(-1))\n","        losses += loss.item()\n","        \n","    return losses / len(data)"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/arifuku/ymmtlab/TransformerAnsys/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]}],"source":["vocab_size_src = len(vocab_src)\n","vocab_size_tgt = len(vocab_tgt)\n","embedding_size = 240\n","nhead = 1\n","dim_feedforward = 100\n","num_encoder_layers = 2\n","num_decoder_layers = 2\n","dropout = 0.1\n","# vocab_size_src = len(vocab_src)\n","# vocab_size_tgt = len(vocab_tgt)\n","# embedding_size = 240\n","# nhead = 8\n","# dim_feedforward = 100\n","# num_encoder_layers = 2\n","# num_decoder_layers = 2\n","# dropout = 0.1\n","\n","model = Seq2SeqTransformer(\n","    num_encoder_layers=num_encoder_layers,\n","    num_decoder_layers=num_decoder_layers,\n","    embedding_size=embedding_size,\n","    vocab_size_src=vocab_size_src, vocab_size_tgt=vocab_size_tgt,\n","    dim_feedforward=dim_feedforward,\n","    dropout=dropout, nhead=nhead\n",")\n","\n","for p in model.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)\n","\n","model = model.to(device)\n","\n","criterion = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n","\n","optimizer = torch.optim.Adam(model.parameters())"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 32.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[1/100] train loss: 1.39, valid loss: 0.71  [2s] counter: 0 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 32.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[2/100] train loss: 0.53, valid loss: 0.12  [2s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 32.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[3/100] train loss: 0.22, valid loss: 0.01  [2s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 32.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[4/100] train loss: 0.15, valid loss: 0.00  [2s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 33.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[5/100] train loss: 0.10, valid loss: 0.00  [2s] counter: 1 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 32.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[6/100] train loss: 0.12, valid loss: 0.00  [2s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 33.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[7/100] train loss: 0.10, valid loss: 0.02  [2s] counter: 2 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 33.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[8/100] train loss: 0.10, valid loss: 0.00  [2s] counter: 3 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 32.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[9/100] train loss: 0.08, valid loss: 0.00  [2s] counter: 4 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 33.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[10/100] train loss: 0.09, valid loss: 0.00  [2s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 33.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[11/100] train loss: 0.06, valid loss: 0.00  [2s] counter: 2 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 33.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[12/100] train loss: 0.06, valid loss: 0.00  [2s] counter: 3 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 32.69it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[13/100] train loss: 0.05, valid loss: 0.00  [2s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 33.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[14/100] train loss: 0.04, valid loss: 0.00  [2s] counter: 2 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 33.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[15/100] train loss: 0.04, valid loss: 0.00  [2s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 32.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[16/100] train loss: 0.03, valid loss: 0.00  [2s] counter: 2 **\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 33.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[17/100] train loss: 0.03, valid loss: 0.00  [2s] counter: 1 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 33.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[18/100] train loss: 0.03, valid loss: 0.00  [2s] counter: 2 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 32.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[19/100] train loss: 0.03, valid loss: 0.00  [2s] counter: 3 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 33.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[20/100] train loss: 0.04, valid loss: 0.00  [2s] counter: 4 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 32.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[21/100] train loss: 0.04, valid loss: 0.00  [2s] counter: 5 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 33.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[22/100] train loss: 0.08, valid loss: 0.00  [2s] counter: 6 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 32.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[23/100] train loss: 0.05, valid loss: 0.00  [2s] counter: 7 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 32.69it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[24/100] train loss: 0.04, valid loss: 0.00  [2s] counter: 8 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 33.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[25/100] train loss: 0.04, valid loss: 0.00  [2s] counter: 9 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 32.74it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[26/100] train loss: 0.06, valid loss: 0.05  [2s] counter: 10 \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:01<00:00, 33.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[27/100] train loss: 0.06, valid loss: 0.00  [2s] counter: 11 \n"]}],"source":["epoch = 100\n","best_loss = float('Inf')\n","best_model = None\n","patience = 10\n","counter = 0\n","\n","for loop in range(1, epoch + 1):\n","    \n","    start_time = time.time()\n","    \n","    loss_train = train(\n","        model=model, data=train_iter, optimizer=optimizer,\n","        criterion=criterion, PAD_IDX=PAD_IDX\n","    )\n","    \n","    elapsed_time = time.time() - start_time\n","    \n","    loss_valid = evaluate(\n","        model=model, data=valid_iter, criterion=criterion, PAD_IDX=PAD_IDX\n","    )\n","    \n","    print('[{}/{}] train loss: {:.2f}, valid loss: {:.2f}  [{}{:.0f}s] counter: {} {}'.format(\n","        loop, epoch,\n","        loss_train, loss_valid,\n","        str(int(math.floor(elapsed_time / 60))) + 'm' if math.floor(elapsed_time / 60) > 0 else '',\n","        elapsed_time % 60,\n","        counter,\n","        '**' if best_loss > loss_valid else ''\n","    ))\n","    \n","    if best_loss > loss_valid:\n","        best_loss = loss_valid\n","        best_model = model\n","        counter = 0\n","        \n","    if counter > patience:\n","        break\n","    \n","    counter += 1"]},{"cell_type":"markdown","metadata":{},"source":["学習したモデルの保存"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[],"source":["torch.save(best_model.state_dict(), model_dir_path.joinpath(version + 'translation_transfomer.pth'))"]},{"cell_type":"markdown","metadata":{},"source":["学習したモデルを使って翻訳をする"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[],"source":["def translate(\n","    model, text, vocab_src, vocab_tgt, seq_len_tgt,\n","    START_IDX, END_IDX\n","):\n","    model.eval()\n","    tokens = convert_text_to_indexes(text, vocab=vocab_src)\n","    num_tokens = len(tokens)\n","\n","    # Tensorに変換\n","    src = torch.LongTensor(tokens).reshape(num_tokens, 1).to(device)\n","    mask_src = torch.zeros((num_tokens, num_tokens), device=device).type(torch.bool)\n","\n","    # デコード\n","    predicts = greedy_decode(\n","        model=model, src=src,\n","        mask_src=mask_src, seq_len_tgt=seq_len_tgt,\n","        START_IDX=START_IDX, END_IDX=END_IDX\n","    ).flatten()\n","\n","    return convert_indexes_to_text(predicts, vocab=vocab_tgt)\n","\n","def greedy_decode(model, src, mask_src, seq_len_tgt, START_IDX, END_IDX):\n","    src = src.to(device)\n","    mask_src = mask_src.to(device)\n","\n","    memory = model.encode(src, mask_src)\n","    ys = torch.ones(1, 1).fill_(START_IDX).type(torch.long).to(device)\n","    \n","    for i in range(seq_len_tgt - 1):\n","        memory = memory.to(device)\n","        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(device).type(torch.bool)\n","        mask_tgt = generate_square_subsequent_mask(ys.size(0)).to(device).type(torch.bool)\n","        \n","        output = model.decode(ys, memory, mask_tgt)\n","        output = output.transpose(0, 1)\n","        output = model.output(output[:, -1])\n","        \n","        # 最も高いスコアのトークンを取得\n","        _, next_word = torch.max(output, dim=1)\n","        next_word = next_word.item()\n","\n","        # 生成されたトークンを追加\n","        ys = torch.cat([ys, torch.ones(1, 1).fill_(next_word).type_as(src.data)], dim=0)\n","        if next_word == END_IDX:\n","            break\n","    \n","    return ys\n"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: 9+4\n","Output: 13\n"]}],"source":["seq_len_tgt = max([len(x[1]) for x in train_data])\n","text = '9+4'\n","\n","# 翻訳を実行\n","translation = translate(\n","    model=best_model, text=text, vocab_src=vocab_src, vocab_tgt=vocab_tgt,\n","    seq_len_tgt=seq_len_tgt,\n","    START_IDX=START_IDX, END_IDX=END_IDX\n",")\n","\n","print(f\"Input: {text}\")\n","print(f\"Output: {translation}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"KantaiBERT_2.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
